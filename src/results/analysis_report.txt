RNN Hyperparameter Analysis Report
==================================================

1. Effect of RNN Layer Count
------------------------------
Results:
  1 layers: Test F1 = 0.1905, Valid F1 = 0.1905
  2 layers: Test F1 = 0.1111, Valid F1 = 0.1111
  3 layers: Test F1 = 0.1111, Valid F1 = 0.1111

Best configuration: 1 layers
Best Test F1 Score: 0.1905
Trend: Performance appears to be decreasing with more layers.

2. Effect of RNN Hidden Units
------------------------------
Results:
  32 units: Test F1 = 0.1111, Valid F1 = 0.1111
  64 units: Test F1 = 0.1905, Valid F1 = 0.1905
  128 units: Test F1 = 0.1667, Valid F1 = 0.1111

Best configuration: 64 units
Best Test F1 Score: 0.1905

3. Effect of Bidirectional RNN
------------------------------
  Unidirectional: Test F1 = 0.1905, Valid F1 = 0.1905
  Bidirectional: Test F1 = 0.1333, Valid F1 = 0.1111

Unidirectional RNN performs 30.0% better than bidirectional.

4. Overall Conclusions
------------------------------
Best overall configuration:
  - Experiment: rnn_layers_1
  - Configuration: {'embedding_dim': 64, 'rnn_units': 32, 'num_rnn_layers': 1, 'bidirectional': False, 'dropout_rate': 0.2, 'activation': 'tanh'}
  - Test F1 Score: 0.1905
  - Test Accuracy: 0.4000

5. Recommendations
------------------------------
Based on the experimental results:
  - Use 1 RNN layer(s) for optimal performance
  - Use 64 hidden units for best results
  - Use unidirectional RNN architecture