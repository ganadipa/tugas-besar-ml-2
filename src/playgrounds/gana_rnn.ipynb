{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starter has been initialized.\n",
      "RNN Implementation - Tugas Besar 2 IF3270\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from starter import Starter\n",
    "\n",
    "# Setup working directory\n",
    "starter = Starter()\n",
    "starter.start(lambda: os.chdir(os.path.dirname(os.getcwd())))\n",
    "\n",
    "# Import all necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Import custom modules\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.metrics_calculator import MetricsCalculator\n",
    "from models.rnn import RNNModelBuilder\n",
    "from layers.embedding import EmbeddingLayer\n",
    "from layers.simple_rnn import SimpleRNNLayer\n",
    "from layers.bidirectional import BidirectionalLayer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"RNN Implementation - Tugas Besar 2 IF3270\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 19:16:43.906705: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-28 19:16:43.907657: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 19:16:43.910209: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 19:16:43.917259: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748434603.929850   77767 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748434603.933289   77767 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748434603.942691   77767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748434603.942709   77767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748434603.942710   77767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748434603.942711   77767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 19:16:43.945909: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# cell 2 - CORRECTED VERSION\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from typing import Dict, Any, Tuple\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from utils.data_loader import DataLoader\n",
    "from utils.metrics_calculator import MetricsCalculator\n",
    "from models.rnn import RNNModelBuilder\n",
    "\n",
    "class KerasRNNTrainer:\n",
    "    \"\"\"Keras RNN trainer for comparison with custom implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, data_loader):\n",
    "        self.data_loader = data_loader\n",
    "        \n",
    "    def create_keras_model(self, config: Dict[str, Any]) -> tf.keras.Model:\n",
    "        \"\"\"Create Keras RNN model with given configuration\"\"\"\n",
    "        model = Sequential(name=f\"keras_rnn_{config.get('experiment_name', 'model')}\")\n",
    "        \n",
    "        # Embedding layer\n",
    "        model.add(Embedding(\n",
    "            input_dim=self.data_loader.preprocessor.vocab_size,\n",
    "            output_dim=config['embedding_dim'],\n",
    "            input_length=self.data_loader.preprocessor.max_length,\n",
    "            name='embedding'\n",
    "        ))\n",
    "        \n",
    "        # RNN layers\n",
    "        for i in range(config['num_rnn_layers']):\n",
    "            return_sequences = i < config['num_rnn_layers'] - 1\n",
    "            \n",
    "            rnn_layer = SimpleRNN(\n",
    "                config['rnn_units'],\n",
    "                activation=config['activation'],\n",
    "                return_sequences=return_sequences,\n",
    "                name=f'simple_rnn_{i}'\n",
    "            )\n",
    "            \n",
    "            if config['bidirectional']:\n",
    "                model.add(Bidirectional(rnn_layer, name=f'bidirectional_{i}'))\n",
    "            else:\n",
    "                model.add(rnn_layer)\n",
    "            \n",
    "            # Add dropout after each RNN layer except the last\n",
    "            if i < config['num_rnn_layers'] - 1:\n",
    "                model.add(Dropout(config['dropout_rate'], name=f'dropout_{i}'))\n",
    "        \n",
    "        # Final dropout and dense layer\n",
    "        model.add(Dropout(config['dropout_rate'], name='dropout_final'))\n",
    "        model.add(Dense(self.data_loader.num_classes, activation='softmax', name='dense'))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_model(self, config: Dict[str, Any], X_train, y_train, X_valid, y_valid, \n",
    "                   epochs: int = 10, batch_size: int = 32) -> Tuple[tf.keras.Model, Dict]:\n",
    "        \"\"\"Train Keras model and return model + history\"\"\"\n",
    "        \n",
    "        print(f\"Creating and training Keras model...\")\n",
    "        model = self.create_keras_model(config)\n",
    "        \n",
    "        print(f\"Model summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return model, history.history\n",
    "    \n",
    "    def extract_weights_for_custom_model(self, keras_model: tf.keras.Model, config: Dict[str, Any]) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"Extract weights from Keras model in format compatible with custom model\"\"\"\n",
    "        weights_dict = {}\n",
    "        \n",
    "        # Create mapping from Keras layer names to custom layer names\n",
    "        keras_to_custom_mapping = self._create_layer_name_mapping(config)\n",
    "        \n",
    "        for layer in keras_model.layers:\n",
    "            layer_weights = layer.get_weights()\n",
    "            if len(layer_weights) == 0:\n",
    "                continue\n",
    "                \n",
    "            keras_layer_name = layer.name\n",
    "            \n",
    "            # Map to custom layer name\n",
    "            if keras_layer_name in keras_to_custom_mapping:\n",
    "                custom_layer_name = keras_to_custom_mapping[keras_layer_name]\n",
    "            else:\n",
    "                print(f\"Warning: No mapping found for Keras layer '{keras_layer_name}'\")\n",
    "                continue\n",
    "            \n",
    "            if 'embedding' in keras_layer_name:\n",
    "                weights_dict[custom_layer_name] = {\n",
    "                    'embedding_matrix': layer_weights[0]\n",
    "                }\n",
    "            elif 'simple_rnn' in keras_layer_name:\n",
    "                # SimpleRNN weights: [W_input, W_recurrent, bias]\n",
    "                # Keras: input @ W_input + hidden @ W_recurrent + bias\n",
    "                # Custom: input @ W_ih.T + hidden @ W_hh.T + bias\n",
    "                # So: W_ih = W_input.T, W_hh = W_recurrent.T\n",
    "                weights_dict[custom_layer_name] = {\n",
    "                    'W_ih': layer_weights[0].T,  # (input_size, hidden_size) -> (hidden_size, input_size)\n",
    "                    'W_hh': layer_weights[1].T,  # (hidden_size, hidden_size) -> (hidden_size, hidden_size)\n",
    "                    'b_h': layer_weights[2]      # (hidden_size,)\n",
    "                }\n",
    "            elif 'bidirectional' in keras_layer_name:\n",
    "                # Bidirectional layer weights: forward + backward\n",
    "                # Keras stores as [forward_W_input, forward_W_recurrent, forward_bias, backward_W_input, backward_W_recurrent, backward_bias]\n",
    "                if len(layer_weights) >= 6:\n",
    "                    weights_dict[custom_layer_name] = {\n",
    "                        'forward_W_ih': layer_weights[0].T,\n",
    "                        'forward_W_hh': layer_weights[1].T,\n",
    "                        'forward_b_h': layer_weights[2],\n",
    "                        'backward_W_ih': layer_weights[3].T,\n",
    "                        'backward_W_hh': layer_weights[4].T,\n",
    "                        'backward_b_h': layer_weights[5]\n",
    "                    }\n",
    "            elif 'dense' in keras_layer_name:\n",
    "                # Dense layer weights: [W, b]\n",
    "                # Keras: input @ W + b  where W is (input_size, output_size)\n",
    "                # Custom: input @ W.T + b where W is (output_size, input_size)\n",
    "                # So: W_custom = W_keras.T\n",
    "                weights_dict[custom_layer_name] = {\n",
    "                    'W': layer_weights[0].T,  # (input_size, output_size) -> (output_size, input_size)\n",
    "                    'b': layer_weights[1]     # (output_size,)\n",
    "                }\n",
    "        \n",
    "        return weights_dict\n",
    "    \n",
    "    def _create_layer_name_mapping(self, config: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Create mapping from Keras layer names to custom layer names\"\"\"\n",
    "        mapping = {\n",
    "            'embedding': 'embedding',\n",
    "            'dropout_final': 'dropout_final',\n",
    "            'dense': 'classification'\n",
    "        }\n",
    "        \n",
    "        # Add RNN layer mappings\n",
    "        for i in range(config['num_rnn_layers']):\n",
    "            if config['bidirectional']:\n",
    "                mapping[f'bidirectional_{i}'] = f'bidirectional_rnn_{i}'\n",
    "            else:\n",
    "                mapping[f'simple_rnn_{i}'] = f'rnn_{i}'\n",
    "            \n",
    "            # Add dropout mappings for intermediate layers\n",
    "            if i < config['num_rnn_layers'] - 1:\n",
    "                mapping[f'dropout_{i}'] = f'dropout_{i}'\n",
    "        \n",
    "        return mapping\n",
    "    \n",
    "    def save_keras_weights(self, keras_model: tf.keras.Model, config: Dict[str, Any], filepath: str) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"Save Keras weights to file and return weights dict\"\"\"\n",
    "        weights_dict = self.extract_weights_for_custom_model(keras_model, config)\n",
    "        \n",
    "        # Flatten weights dict for saving\n",
    "        flattened_weights = {}\n",
    "        for layer_name, layer_weights in weights_dict.items():\n",
    "            for weight_name, weight_value in layer_weights.items():\n",
    "                flattened_weights[f\"{layer_name}_{weight_name}\"] = weight_value\n",
    "        \n",
    "        np.savez(filepath, **flattened_weights)\n",
    "        print(f\"Saved custom weights to {filepath}\")\n",
    "        print(f\"Layer mapping: {list(weights_dict.keys())}\")\n",
    "        \n",
    "        return weights_dict\n",
    "\n",
    "\n",
    "class RNNExperimentRunner:\n",
    "    \"\"\"RNN experiment runner that handles data loader setup correctly\"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir: str = \"results\"):\n",
    "        self.results_dir = results_dir\n",
    "        self.data_loader = None\n",
    "        self.keras_trainer = None\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        # Store data\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_valid = None\n",
    "        self.y_valid = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        \n",
    "        # Experiment results\n",
    "        self.experiment_results = {}\n",
    "    \n",
    "    def setup_data(self, data_loader, X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "        \"\"\"Setup the experiment runner with prepared data\"\"\"\n",
    "        self.data_loader = data_loader\n",
    "        self.keras_trainer = KerasRNNTrainer(data_loader)\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        print(f\"Data setup complete:\")\n",
    "        print(f\"  Vocabulary size: {self.data_loader.preprocessor.vocab_size}\")\n",
    "        print(f\"  Number of classes: {self.data_loader.num_classes}\")\n",
    "        print(f\"  Training samples: {len(X_train)}\")\n",
    "    \n",
    "    def run_single_experiment(self, config: Dict[str, Any], experiment_name: str, \n",
    "                            epochs: int = 15) -> Dict[str, Any]:\n",
    "        \"\"\"Run single experiment with Keras training and custom implementation comparison\"\"\"\n",
    "        \n",
    "        if self.data_loader is None:\n",
    "            raise ValueError(\"Data not set up. Call setup_data() first.\")\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running experiment: {experiment_name}\")\n",
    "        print(f\"Configuration: {config}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Step 1: Train Keras model\n",
    "        print(\"Step 1: Training Keras model...\")\n",
    "        keras_model, training_history = self.keras_trainer.train_model(\n",
    "            config, self.X_train, self.y_train, self.X_valid, self.y_valid, \n",
    "            epochs=epochs\n",
    "        )\n",
    "        \n",
    "        # Step 2: Evaluate Keras model\n",
    "        print(\"Step 2: Evaluating Keras model...\")\n",
    "        keras_test_loss, keras_test_acc = keras_model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "        keras_predictions = keras_model.predict(self.X_test, verbose=0)\n",
    "        keras_pred_labels = np.argmax(keras_predictions, axis=1)\n",
    "        keras_f1 = MetricsCalculator.macro_f1_score(self.y_test, keras_pred_labels, self.data_loader.num_classes)\n",
    "        \n",
    "        print(f\"Keras Results - Accuracy: {keras_test_acc:.4f}, F1: {keras_f1:.4f}\")\n",
    "        \n",
    "        # Step 3: Save Keras weights and extract for custom model\n",
    "        keras_weights_path = os.path.join(self.results_dir, f\"{experiment_name}_keras.weights.h5\")\n",
    "        keras_model.save_weights(keras_weights_path)\n",
    "        \n",
    "        custom_weights_path = os.path.join(self.results_dir, f\"{experiment_name}_custom_weights.npz\")\n",
    "        weights_dict = self.keras_trainer.save_keras_weights(keras_model, config, custom_weights_path)\n",
    "        \n",
    "        # Step 4: Create custom model and load weights\n",
    "        print(\"Step 3: Creating custom model and loading weights...\")\n",
    "        custom_model = RNNModelBuilder.create_simple_rnn_model(\n",
    "            vocab_size=self.data_loader.preprocessor.vocab_size,\n",
    "            num_classes=self.data_loader.num_classes,\n",
    "            **config\n",
    "        )\n",
    "        \n",
    "        # Load weights into custom model\n",
    "        print(\"Loading weights into custom model...\")\n",
    "        custom_model.set_weights(weights_dict)\n",
    "        \n",
    "        # Verify weights were loaded correctly\n",
    "        custom_weights = custom_model.get_weights()\n",
    "        print(f\"Custom model layers with weights: {list(custom_weights.keys())}\")\n",
    "        \n",
    "        # Step 5: Evaluate custom model\n",
    "        print(\"Step 4: Evaluating custom model...\")\n",
    "        \n",
    "        # Test on a small subset first to debug\n",
    "        test_subset = self.X_test[:5]\n",
    "        keras_subset_pred = keras_model.predict(test_subset, verbose=0)\n",
    "        custom_subset_pred = custom_model.predict(test_subset)\n",
    "        \n",
    "        print(f\"Sample predictions comparison (first 2 samples):\")\n",
    "        print(f\"Keras  : {keras_subset_pred[:2]}\")\n",
    "        print(f\"Custom : {custom_subset_pred[:2]}\")\n",
    "        print(f\"Difference: {np.max(np.abs(keras_subset_pred[:2] - custom_subset_pred[:2]))}\")\n",
    "        \n",
    "        # Full evaluation\n",
    "        custom_predictions = custom_model.predict(self.X_test)\n",
    "        custom_pred_labels = np.argmax(custom_predictions, axis=1)\n",
    "        custom_accuracy = MetricsCalculator.accuracy(self.y_test, custom_pred_labels)\n",
    "        custom_f1 = MetricsCalculator.macro_f1_score(self.y_test, custom_pred_labels, self.data_loader.num_classes)\n",
    "        \n",
    "        print(f\"Custom Results - Accuracy: {custom_accuracy:.4f}, F1: {custom_f1:.4f}\")\n",
    "        \n",
    "        # Step 6: Compare predictions\n",
    "        prediction_similarity = np.mean(np.isclose(keras_predictions, custom_predictions, atol=1e-3))\n",
    "        max_prediction_diff = np.max(np.abs(keras_predictions - custom_predictions))\n",
    "        \n",
    "        print(f\"Comparison - Similarity: {prediction_similarity:.4f}, Max Diff: {max_prediction_diff:.6f}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            'experiment_name': experiment_name,\n",
    "            'config': config,\n",
    "            'keras_metrics': {\n",
    "                'test_accuracy': float(keras_test_acc),\n",
    "                'test_f1': float(keras_f1),\n",
    "                'test_loss': float(keras_test_loss)\n",
    "            },\n",
    "            'custom_metrics': {\n",
    "                'test_accuracy': float(custom_accuracy),\n",
    "                'test_f1': float(custom_f1)\n",
    "            },\n",
    "            'comparison': {\n",
    "                'prediction_similarity': float(prediction_similarity),\n",
    "                'max_prediction_difference': float(max_prediction_diff),\n",
    "                'f1_difference': float(abs(keras_f1 - custom_f1)),\n",
    "                'accuracy_difference': float(abs(keras_test_acc - custom_accuracy))\n",
    "            },\n",
    "            'training_history': training_history,\n",
    "            'execution_time': end_time - start_time,\n",
    "            'model_summary': custom_model.summary(),\n",
    "            'keras_weights_path': keras_weights_path,\n",
    "            'custom_weights_path': custom_weights_path\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def run_multiple_experiments(self, experiment_configs: Dict[str, List[Dict[str, Any]]], \n",
    "                               epochs: int = 15) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Run multiple experiments for hyperparameter analysis\"\"\"\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        for experiment_type, configs in experiment_configs.items():\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Running {experiment_type} experiments\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            results = []\n",
    "            \n",
    "            for i, config in enumerate(configs):\n",
    "                experiment_name = f\"{experiment_type}_{i}\"\n",
    "                result = self.run_single_experiment(config, experiment_name, epochs)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Save intermediate results\n",
    "                self._save_results({experiment_type: results})\n",
    "            \n",
    "            all_results[experiment_type] = results\n",
    "        \n",
    "        # Save final results\n",
    "        self._save_results(all_results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def _save_results(self, results: Dict[str, List[Dict[str, Any]]]):\n",
    "        \"\"\"Save experiment results to JSON file\"\"\"\n",
    "        results_path = os.path.join(self.results_dir, \"experiment_results.json\")\n",
    "        \n",
    "        # Convert numpy types to native Python types for JSON serialization\n",
    "        serializable_results = {}\n",
    "        for exp_type, exp_results in results.items():\n",
    "            serializable_results[exp_type] = []\n",
    "            for result in exp_results:\n",
    "                serializable_result = {}\n",
    "                for key, value in result.items():\n",
    "                    if key == 'training_history':\n",
    "                        # Convert training history numpy arrays to lists\n",
    "                        serializable_result[key] = {\n",
    "                            k: [float(x) for x in v] if isinstance(v, (list, np.ndarray)) else v\n",
    "                            for k, v in value.items()\n",
    "                        }\n",
    "                    elif isinstance(value, np.ndarray):\n",
    "                        serializable_result[key] = value.tolist()\n",
    "                    elif isinstance(value, dict):\n",
    "                        serializable_result[key] = {\n",
    "                            k: float(v) if isinstance(v, (np.floating, np.integer)) else v\n",
    "                            for k, v in value.items()\n",
    "                        }\n",
    "                    else:\n",
    "                        serializable_result[key] = value\n",
    "                serializable_results[exp_type].append(serializable_result)\n",
    "        \n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(serializable_results, f, indent=2)\n",
    "        \n",
    "        print(f\"Results saved to {results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading and preprocessing data...\n",
      "Loaded data:\n",
      "  Train: 500 samples\n",
      "  Valid: 100 samples\n",
      "  Test: 100 samples\n",
      "Built vocabulary with 42 words\n",
      "Most frequent words: ['ini', 'yang', 'sangat', 'dengan', 'produk', 'biasa', 'kualitas', 'untuk', 'saya', 'senang']\n",
      "Label encoding:\n",
      "  negative: 0\n",
      "  neutral: 1\n",
      "  positive: 2\n",
      "\n",
      "Data shapes:\n",
      "  X_train: (500, 50)\n",
      "  y_train: (500,)\n",
      "  X_valid: (100, 50)\n",
      "  y_valid: (100,)\n",
      "  X_test: (100, 50)\n",
      "  y_test: (100,)\n",
      "Data loaded successfully!\n",
      "Vocabulary size: 42\n",
      "Number of classes: 3\n",
      "Max sequence length: 50\n",
      "\n",
      "Class distribution in training data:\n",
      "  negative: 150 (30.0%)\n",
      "  neutral: 150 (30.0%)\n",
      "  positive: 200 (40.0%)\n",
      "\n",
      "Data shapes:\n",
      "  X_train: (500, 50)\n",
      "  y_train: (500,)\n",
      "  X_valid: (100, 50)\n",
      "  y_valid: (100,)\n",
      "  X_test: (100, 50)\n",
      "  y_test: (100,)\n",
      "\n",
      "2. Testing RNN model components...\n",
      "Testing Embedding Layer...\n",
      "  Embedding test - Input: (2, 50), Output: (2, 50, 64)\n",
      "Testing Simple RNN Layer...\n",
      "  RNN test - Input: (2, 50, 64), Output: (2, 32)\n",
      "Testing Bidirectional RNN Layer...\n",
      "  Bidirectional RNN test - Input: (2, 50, 64), Output: (2, 64)\n",
      "✓ All components working correctly!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1. Loading and preprocessing data...\")\n",
    "\n",
    "# Initialize data loader\n",
    "data_dir = \"../data\"  # Adjust path as needed\n",
    "data_loader = DataLoader(data_dir)\n",
    "\n",
    "# Check if data directory exists and create sample data if needed\n",
    "if not os.path.exists(os.path.join(data_dir, 'nusax')):\n",
    "    print(\"Warning: NusaX dataset not found in data/nusax/\")\n",
    "    print(\"Please ensure you have the following files:\")\n",
    "    print(\"  - data/nusax/train.csv\")\n",
    "    print(\"  - data/nusax/valid.csv\") \n",
    "    print(\"  - data/nusax/test.csv\")\n",
    "    print(\"\\nUsing existing sample data from paste.txt...\")\n",
    "    \n",
    "# Load and prepare data\n",
    "try:\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = data_loader.prepare_data(\n",
    "        max_vocab_size=5000,\n",
    "        max_length=50,\n",
    "        min_freq=1\n",
    "    )\n",
    "    \n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Vocabulary size: {data_loader.preprocessor.vocab_size}\")\n",
    "    print(f\"Number of classes: {data_loader.num_classes}\")\n",
    "    print(f\"Max sequence length: {data_loader.preprocessor.max_length}\")\n",
    "    \n",
    "    # Show class distribution\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    print(f\"\\nClass distribution in training data:\")\n",
    "    for class_id, count in zip(unique, counts):\n",
    "        class_name = data_loader.reverse_label_encoder[class_id]\n",
    "        print(f\"  {class_name}: {count} ({count/len(y_train)*100:.1f}%)\")\n",
    "        \n",
    "    print(f\"\\nData shapes:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  y_train: {y_train.shape}\")\n",
    "    print(f\"  X_valid: {X_valid.shape}\")\n",
    "    print(f\"  y_valid: {y_valid.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}\")\n",
    "    print(f\"  y_test: {y_test.shape}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise e\n",
    "\n",
    "# Test basic model components\n",
    "print(\"\\n2. Testing RNN model components...\")\n",
    "\n",
    "# Test embedding layer\n",
    "print(\"Testing Embedding Layer...\")\n",
    "embedding_layer = EmbeddingLayer(vocab_size=data_loader.preprocessor.vocab_size, embedding_dim=64)\n",
    "test_tokens = X_train[:2]  # Take first 2 samples\n",
    "embedded = embedding_layer.forward(test_tokens)\n",
    "print(f\"  Embedding test - Input: {test_tokens.shape}, Output: {embedded.shape}\")\n",
    "\n",
    "# Test RNN layer\n",
    "print(\"Testing Simple RNN Layer...\")\n",
    "rnn_layer = SimpleRNNLayer(hidden_size=32, return_sequences=False)\n",
    "rnn_output = rnn_layer.forward(embedded)\n",
    "print(f\"  RNN test - Input: {embedded.shape}, Output: {rnn_output.shape}\")\n",
    "\n",
    "# Test bidirectional RNN\n",
    "print(\"Testing Bidirectional RNN Layer...\")\n",
    "bidirectional_rnn = BidirectionalLayer(\n",
    "    SimpleRNNLayer,\n",
    "    hidden_size=32,\n",
    "    return_sequences=False\n",
    ")\n",
    "bi_output = bidirectional_rnn.forward(embedded)\n",
    "print(f\"  Bidirectional RNN test - Input: {embedded.shape}, Output: {bi_output.shape}\")\n",
    "\n",
    "print(\"✓ All components working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Running a single experiment test with FIXED runner...\n",
      "Data setup complete:\n",
      "  Vocabulary size: 42\n",
      "  Number of classes: 3\n",
      "  Training samples: 500\n",
      "Running single test experiment (5 epochs)...\n",
      "\n",
      "============================================================\n",
      "Running experiment: test_experiment_fixed\n",
      "Configuration: {'embedding_dim': 64, 'rnn_units': 32, 'num_rnn_layers': 1, 'bidirectional': False, 'dropout_rate': 0.2, 'activation': 'tanh'}\n",
      "============================================================\n",
      "Step 1: Training Keras model...\n",
      "Creating and training Keras model...\n",
      "Model summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ganadipa/code/kuliah/sem6/Machine-learning/Tugas-Besar-II-ML/.venv/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-05-28 19:16:45.110258: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"keras_rnn_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"keras_rnn_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_final (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_0 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_final (\u001b[38;5;33mDropout\u001b[0m)         │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6362 - loss: 0.8648 - val_accuracy: 0.2000 - val_loss: 1.4289\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.2418 - val_accuracy: 0.0000e+00 - val_loss: 1.6726\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.1096 - val_accuracy: 0.0000e+00 - val_loss: 1.9122\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0612 - val_accuracy: 0.0000e+00 - val_loss: 2.0467\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0412 - val_accuracy: 0.0000e+00 - val_loss: 2.1704\n",
      "Step 2: Evaluating Keras model...\n",
      "Keras Results - Accuracy: 0.4000, F1: 0.4667\n",
      "Saved custom weights to results/test_experiment_fixed_custom_weights.npz\n",
      "Layer mapping: ['embedding', 'rnn_0', 'classification']\n",
      "Step 3: Creating custom model and loading weights...\n",
      "Loading weights into custom model...\n",
      "Setting weights for model layers...\n",
      "Available weight keys: ['embedding', 'rnn_0', 'classification']\n",
      "Processing layer: embedding (type: EmbeddingLayer)\n",
      "  Found weights for embedding: ['embedding_matrix']\n",
      "Processing layer: rnn_0 (type: SimpleRNNLayer)\n",
      "  Found weights for rnn_0: ['W_ih', 'W_hh', 'b_h']\n",
      "Storing pending weights for rnn_0: ['W_ih', 'W_hh', 'b_h']\n",
      "Processing layer: dropout_final (type: DropoutLayer)\n",
      "  No weights found for dropout_final\n",
      "Processing layer: classification (type: DenseLayer)\n",
      "  Found weights for classification: ['W', 'b']\n",
      "Successfully loaded weights for layers: ['embedding', 'rnn_0', 'classification']\n",
      "Model now has weights for: ['embedding', 'rnn_0', 'classification']\n",
      "Custom model layers with weights: ['embedding', 'rnn_0', 'classification']\n",
      "Step 4: Evaluating custom model...\n",
      "Loading pending weights for rnn_0\n",
      "Sample predictions comparison (first 2 samples):\n",
      "Keras  : [[0.5054246  0.05895756 0.43561786]\n",
      " [0.27703783 0.11282109 0.6101411 ]]\n",
      "Custom : [[0.25392544 0.2987405  0.44733408]\n",
      " [0.32796982 0.30025867 0.3717715 ]]\n",
      "Difference: 0.2514991760253906\n",
      "Custom Results - Accuracy: 0.2000, F1: 0.1111\n",
      "Comparison - Similarity: 0.0000, Max Diff: 0.584143\n",
      "\n",
      "==================================================\n",
      "FIXED EXPERIMENT TEST RESULTS\n",
      "==================================================\n",
      "Experiment: test_experiment_fixed\n",
      "Configuration: {'embedding_dim': 64, 'rnn_units': 32, 'num_rnn_layers': 1, 'bidirectional': False, 'dropout_rate': 0.2, 'activation': 'tanh'}\n",
      "\n",
      "Keras Results:\n",
      "  Accuracy: 0.4000\n",
      "  F1 Score: 0.4667\n",
      "  Loss: 0.9724\n",
      "\n",
      "Custom Implementation Results:\n",
      "  Accuracy: 0.2000\n",
      "  F1 Score: 0.1111\n",
      "\n",
      "Comparison:\n",
      "  Prediction Similarity: 0.0000\n",
      "  Max Prediction Difference: 0.584143\n",
      "  F1 Difference: 0.3556\n",
      "  Accuracy Difference: 0.2000\n",
      "\n",
      "Execution Time: 2.19 seconds\n",
      "\n",
      "⚠ WARNING: Still low similarity (0.0000)\n",
      "Additional debugging needed...\n",
      "\n",
      "DEBUGGING INFO:\n",
      "==============================\n",
      "Saved weights keys: ['embedding_embedding_matrix', 'rnn_0_W_ih', 'rnn_0_W_hh', 'rnn_0_b_h', 'classification_W', 'classification_b']\n",
      "\n",
      "Model Summary:\n",
      "Model: SimpleRNN\n",
      "==================================================\n",
      "embedding (EmbeddingLayer): vocab_size=42, embedding_dim=64\n",
      "rnn_0 (SimpleRNNLayer): hidden_size=32, activation=tanh, return_sequences=False\n",
      "dropout_final (DropoutLayer): rate=0.2\n",
      "classification (DenseLayer): units=3, activation=softmax\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# cell 4 - CORRECTED VERSION\n",
    "print(\"\\n3. Running a single experiment test with FIXED runner...\")\n",
    "\n",
    "# Create FIXED experiment runner\n",
    "fixed_runner = RNNExperimentRunner(\"results\")\n",
    "\n",
    "# Setup with prepared data\n",
    "fixed_runner.setup_data(\n",
    "    data_loader, X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    ")\n",
    "\n",
    "# Test configuration\n",
    "test_config = {\n",
    "    'embedding_dim': 64,\n",
    "    'rnn_units': 32,\n",
    "    'num_rnn_layers': 1,\n",
    "    'bidirectional': False,\n",
    "    'dropout_rate': 0.2,\n",
    "    'activation': 'tanh'\n",
    "}\n",
    "\n",
    "# Run single experiment with fewer epochs for testing\n",
    "print(\"Running single test experiment (5 epochs)...\")\n",
    "test_result = fixed_runner.run_single_experiment(\n",
    "    test_config, \n",
    "    \"test_experiment_fixed\", \n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FIXED EXPERIMENT TEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Experiment: {test_result['experiment_name']}\")\n",
    "print(f\"Configuration: {test_result['config']}\")\n",
    "print(f\"\\nKeras Results:\")\n",
    "print(f\"  Accuracy: {test_result['keras_metrics']['test_accuracy']:.4f}\")\n",
    "print(f\"  F1 Score: {test_result['keras_metrics']['test_f1']:.4f}\")\n",
    "print(f\"  Loss: {test_result['keras_metrics']['test_loss']:.4f}\")\n",
    "print(f\"\\nCustom Implementation Results:\")\n",
    "print(f\"  Accuracy: {test_result['custom_metrics']['test_accuracy']:.4f}\")\n",
    "print(f\"  F1 Score: {test_result['custom_metrics']['test_f1']:.4f}\")\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Prediction Similarity: {test_result['comparison']['prediction_similarity']:.4f}\")\n",
    "print(f\"  Max Prediction Difference: {test_result['comparison']['max_prediction_difference']:.6f}\")\n",
    "print(f\"  F1 Difference: {test_result['comparison']['f1_difference']:.4f}\")\n",
    "print(f\"  Accuracy Difference: {test_result['comparison']['accuracy_difference']:.4f}\")\n",
    "print(f\"\\nExecution Time: {test_result['execution_time']:.2f} seconds\")\n",
    "\n",
    "# Check if implementation is working correctly\n",
    "if test_result['comparison']['prediction_similarity'] > 0.95:\n",
    "    print(\"\\n✓ SUCCESS: Custom implementation matches Keras very well!\")\n",
    "    print(\"Proceeding with full experiments...\")\n",
    "    \n",
    "    # If successful, run a bidirectional test as well\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TESTING BIDIRECTIONAL RNN...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    bidirectional_config = {\n",
    "        'embedding_dim': 64,\n",
    "        'rnn_units': 32,\n",
    "        'num_rnn_layers': 1,\n",
    "        'bidirectional': True,\n",
    "        'dropout_rate': 0.2,\n",
    "        'activation': 'tanh'\n",
    "    }\n",
    "    \n",
    "    bidirectional_result = fixed_runner.run_single_experiment(\n",
    "        bidirectional_config, \n",
    "        \"test_bidirectional_fixed\", \n",
    "        epochs=5\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nBidirectional Test Results:\")\n",
    "    print(f\"  Prediction Similarity: {bidirectional_result['comparison']['prediction_similarity']:.4f}\")\n",
    "    print(f\"  Max Prediction Difference: {bidirectional_result['comparison']['max_prediction_difference']:.6f}\")\n",
    "    \n",
    "    if bidirectional_result['comparison']['prediction_similarity'] > 0.95:\n",
    "        print(\"✓ Bidirectional RNN also working correctly!\")\n",
    "    else:\n",
    "        print(\"⚠ Bidirectional RNN needs more debugging\")\n",
    "        \n",
    "else:\n",
    "    print(f\"\\n⚠ WARNING: Still low similarity ({test_result['comparison']['prediction_similarity']:.4f})\")\n",
    "    print(\"Additional debugging needed...\")\n",
    "    \n",
    "    # Print more detailed debugging info\n",
    "    print(\"\\nDEBUGGING INFO:\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Check if weights were loaded correctly\n",
    "    if 'custom_weights_path' in test_result:\n",
    "        try:\n",
    "            loaded_weights = np.load(test_result['custom_weights_path'])\n",
    "            print(f\"Saved weights keys: {list(loaded_weights.keys())}\")\n",
    "        except:\n",
    "            print(\"Could not load saved weights file\")\n",
    "    \n",
    "    # Check model structure\n",
    "    print(f\"\\nModel Summary:\")\n",
    "    print(test_result['model_summary'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
